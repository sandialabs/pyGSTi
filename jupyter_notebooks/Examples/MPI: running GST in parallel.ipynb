{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Parallel GST using MPI\n",
    "The purpose of this tutorial is to demonstrate how to compute GST estimates in parallel (using multiple CPUs or \"processors\").  The core PyGSTi computational routines are written to take advantage of multiple processors via the MPI communication framework, and so one must have a version of MPI and the `mpi4py` python package installed in order use run pyGSTi calculations in parallel.  \n",
    "\n",
    "Since `mpi4py` doesn't play nicely with Jupyter notebooks, this tutorial is a bit more clunky than the others.  In it, we will create a standalone Python script that imports `mpi4py` and execute it.\n",
    "\n",
    "We will use as an example the same \"standard\" single-qubit gate set of the first tutorial.  We'll first create a dataset, and then a script to be run in parallel which loads the data.  The creation of a simulated data is performed in the same way as the first tutorial.   Since *random* numbers are generated and used as simulated counts within the call to `generate_fake_data`, it is important that this is *not* done in a parallel environment, or different CPUs may get different data sets.  (This isn't an issue in the typical situation when the data is obtained experimentally.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Import pyGSTi and the \"stardard 1-qubit quantities for a gateset with X(pi/2), Y(pi/2), and idle gates\"\n",
    "import pygsti\n",
    "from pygsti.construction import std1Q_XYI\n",
    "\n",
    "#Create a data set\n",
    "gs_target = std1Q_XYI.gs_target\n",
    "fiducials = std1Q_XYI.fiducials\n",
    "germs = std1Q_XYI.germs\n",
    "maxLengths = [1,2,4,8,16,32]\n",
    "\n",
    "gs_datagen = gs_target.depolarize(gate_noise=0.1, spam_noise=0.001)\n",
    "listOfExperiments = pygsti.construction.make_lsgst_experiment_list(gs_target.gates.keys(), fiducials, fiducials, germs, maxLengths)\n",
    "ds = pygsti.construction.generate_fake_data(gs_datagen, listOfExperiments, nSamples=1000,\n",
    "                                            sampleError=\"binomial\", seed=1234)\n",
    "pygsti.io.write_dataset(\"example_files/mpi_example_dataset.txt\", ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next, we'll write a Python script that will load in the just-created `DataSet`, run GST on it, and write the output to a file.  The only major difference between the contents of this script and previous examples is that the script imports `mpi4py` and passes a MPI comm object (`comm`) to the `do_long_sequence_gst` function.  Since parallel computing is best used for computationaly intensive GST calculations, we also demonstrate how to set a per-processor memory limit to tell pyGSTi to partition its computations so as to not exceed this memory usage.  Lastly, note the use of the `gaugeOptParams` argument of `do_long_sequence_gst`, which can be used to weight different gate set members differently during gauge optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mpiScript = \"\"\"\n",
    "import time\n",
    "import pygsti\n",
    "from pygsti.construction import std1Q_XYI\n",
    "\n",
    "#get MPI comm\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "\n",
    "print(\"Rank %d started\" % comm.Get_rank())\n",
    "\n",
    "#define target gateset, fiducials, and germs as before\n",
    "gs_target = std1Q_XYI.gs_target\n",
    "fiducials = std1Q_XYI.fiducials\n",
    "germs = std1Q_XYI.germs\n",
    "maxLengths = [1,2,4,8,16,32]\n",
    "\n",
    "#tell gauge optimization to weight the gate matrix\n",
    "# elements 100x more heavily than the SPAM vector elements, and\n",
    "# to specifically weight the Gx gate twice as heavily as the other\n",
    "# gates.\n",
    "goParams = {'itemWeights':{'spam': 0.01, 'gates': 1.0, 'Gx': 2.0} }\n",
    "\n",
    "#Specify a per-core memory limit (useful for larger GST calculations)\n",
    "memLim = 2.1*(1024)**3  # 2.1 GB\n",
    "\n",
    "#Perform TP-constrained GST\n",
    "gs_target.set_all_parameterizations(\"TP\")\n",
    "    \n",
    "#load the dataset\n",
    "ds = pygsti.io.load_dataset(\"example_files/mpi_example_dataset.txt\")\n",
    "\n",
    "start = time.time()\n",
    "results = pygsti.do_long_sequence_gst(ds, gs_target, fiducials, fiducials,\n",
    "                                      germs, maxLengths,memLimit=memLim,\n",
    "                                      gaugeOptParams=goParams, comm=comm,\n",
    "                                      verbosity=2)\n",
    "end = time.time()\n",
    "print(\"Rank %d finished in %.1fs\" % (comm.Get_rank(), end-start))\n",
    "if comm.Get_rank() == 0:\n",
    "    import pickle\n",
    "    pickle.dump(results, open(\"example_files/mpi_example_results.pkl\",\"wb\"))\n",
    "\"\"\"\n",
    "with open(\"example_files/mpi_example_script.py\",\"w\") as f:\n",
    "    f.write(mpiScript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next, we run the script with 3 processors using `mpiexec`.  The `mpiexec` executable should have been installed with your MPI distribution -- if it doesn't exist, try replacing `mpiexec` with `mpirun`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 started\n",
      "Rank 1 started\n",
      "Rank 2 started\n",
      "--- Gate Sequence Creation ---\n",
      " 1585 sequences created\n",
      " Dataset has 1585 entries: 1585 utilized, 0 requested sequences were missing\n",
      "--- Gate Sequence Creation ---\n",
      " 1585 sequences created\n",
      " Dataset has 1585 entries: 1585 utilized, 0 requested sequences were missing\n",
      "--- LGST ---\n",
      "--- Gate Sequence Creation ---\n",
      " 1585 sequences created\n",
      " Dataset has 1585 entries: 1585 utilized, 0 requested sequences were missing\n",
      "  Singular values of I_tilde (truncating to first 4 of 6) = \n",
      "  4.24507306085\n",
      "  1.15858456866\n",
      "  0.96719520065\n",
      "  0.921798550187\n",
      "  0.070140897297\n",
      "  0.0208719086309\n",
      "  \n",
      "  Singular values of target I_tilde (truncating to first 4 of 6) = \n",
      "  4.24264068712\n",
      "  1.41421356237\n",
      "  1.41421356237\n",
      "  1.41421356237\n",
      "  3.03015102482e-16\n",
      "  7.09307430818e-17\n",
      "  \n",
      "--- Iterative MLGST: Iter 1 of 6  92 gate strings ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "  Memory limit = 2.10GB\n",
      "  Cur, Persist, Gather = 0.10, 0.00, 0.21 GB\n",
      "  Evaltree generation (deriv) w/mem limit = 1.79GB\n",
      "   mem(1 subtrees, 3,1 param-grps, 1 proc-grps) in 0s = 0.00GB (0.00GB fc)\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 3 procs into 1 (subtree-processing)\n",
      "   groups of ~3 procs each, to distribute over 43 params (taken as 3 param groups of ~14 params).\n",
      "   Memory estimate = 0.00GB (cache=92, wrtLen1=15, wrtLen2=43, subsPerProc=1).\n",
      "  Finding num_nongauge_params is too expensive: using total params.\n",
      "  Sum of Chi^2 = 86.1192 (92 data params - 43 model params = expected mean of 49; p-value = 0.00083297)\n",
      "  Completed in 0.1s\n",
      "  2*Delta(log(L)) = 86.4539\n",
      "  Iteration 1 took 0.1s\n",
      "  \n",
      "--- Iterative MLGST: Iter 2 of 6  168 gate strings ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "  Memory limit = 2.10GB\n",
      "  Cur, Persist, Gather = 0.10, 0.00, 0.21 GB\n",
      "  Evaltree generation (deriv) w/mem limit = 1.79GB\n",
      "   mem(1 subtrees, 3,1 param-grps, 1 proc-grps) in 0s = 0.00GB (0.00GB fc)\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 3 procs into 1 (subtree-processing)\n",
      "   groups of ~3 procs each, to distribute over 43 params (taken as 3 param groups of ~14 params).\n",
      "   Memory estimate = 0.00GB (cache=168, wrtLen1=15, wrtLen2=43, subsPerProc=1).\n",
      "  Finding num_nongauge_params is too expensive: using total params.\n",
      "  Sum of Chi^2 = 163.489 (168 data params - 43 model params = expected mean of 125; p-value = 0.0118281)\n",
      "  Completed in 0.1s\n",
      "  2*Delta(log(L)) = 164.07\n",
      "  Iteration 2 took 0.1s\n",
      "  \n",
      "--- Iterative MLGST: Iter 3 of 6  441 gate strings ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "  Memory limit = 2.10GB\n",
      "  Cur, Persist, Gather = 0.10, 0.00, 0.21 GB\n",
      "  Evaltree generation (deriv) w/mem limit = 1.78GB\n",
      "   mem(1 subtrees, 3,1 param-grps, 1 proc-grps) in 0s = 0.00GB (0.00GB fc)\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 3 procs into 1 (subtree-processing)\n",
      "   groups of ~3 procs each, to distribute over 43 params (taken as 3 param groups of ~14 params).\n",
      "   Memory estimate = 0.00GB (cache=441, wrtLen1=15, wrtLen2=43, subsPerProc=1).\n",
      "  Finding num_nongauge_params is too expensive: using total params.\n",
      "  Sum of Chi^2 = 446.448 (441 data params - 43 model params = expected mean of 398; p-value = 0.04692)\n",
      "  Completed in 0.1s\n",
      "  2*Delta(log(L)) = 447.175\n",
      "  Iteration 3 took 0.1s\n",
      "  \n",
      "--- Iterative MLGST: Iter 4 of 6  817 gate strings ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "  Memory limit = 2.10GB\n",
      "  Cur, Persist, Gather = 0.11, 0.00, 0.21 GB\n",
      "  Evaltree generation (deriv) w/mem limit = 1.78GB\n",
      "   mem(1 subtrees, 3,1 param-grps, 1 proc-grps) in 0s = 0.00GB (0.00GB fc)\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 3 procs into 1 (subtree-processing)\n",
      "   groups of ~3 procs each, to distribute over 43 params (taken as 3 param groups of ~14 params).\n",
      "   Memory estimate = 0.00GB (cache=823, wrtLen1=15, wrtLen2=43, subsPerProc=1).\n",
      "  Finding num_nongauge_params is too expensive: using total params.\n",
      "  Sum of Chi^2 = 818.354 (817 data params - 43 model params = expected mean of 774; p-value = 0.130643)\n",
      "  Completed in 0.2s\n",
      "  2*Delta(log(L)) = 819.274\n",
      "  Iteration 4 took 0.2s\n",
      "  \n",
      "--- Iterative MLGST: Iter 5 of 6  1201 gate strings ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "  Memory limit = 2.10GB\n",
      "  Cur, Persist, Gather = 0.11, 0.00, 0.21 GB\n",
      "  Evaltree generation (deriv) w/mem limit = 1.78GB\n",
      "   mem(1 subtrees, 3,1 param-grps, 1 proc-grps) in 0s = 0.00GB (0.00GB fc)\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 3 procs into 1 (subtree-processing)\n",
      "   groups of ~3 procs each, to distribute over 43 params (taken as 3 param groups of ~14 params).\n",
      "   Memory estimate = 0.00GB (cache=1279, wrtLen1=15, wrtLen2=43, subsPerProc=1).\n",
      "  Finding num_nongauge_params is too expensive: using total params.\n",
      "  Sum of Chi^2 = 1217.96 (1201 data params - 43 model params = expected mean of 1158; p-value = 0.107705)\n",
      "  Completed in 0.2s\n",
      "  2*Delta(log(L)) = 1218.95\n",
      "  Iteration 5 took 0.3s\n",
      "  \n",
      "--- Iterative MLGST: Iter 6 of 6  1585 gate strings ---: \n",
      "  --- Minimum Chi^2 GST ---\n",
      "  Memory limit = 2.10GB\n",
      "  Cur, Persist, Gather = 0.11, 0.00, 0.21 GB\n",
      "  Evaltree generation (deriv) w/mem limit = 1.78GB\n",
      "   mem(1 subtrees, 3,1 param-grps, 1 proc-grps) in 0s = 0.00GB (0.00GB fc)\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 3 procs into 1 (subtree-processing)\n",
      "   groups of ~3 procs each, to distribute over 43 params (taken as 3 param groups of ~14 params).\n",
      "   Memory estimate = 0.00GB (cache=1810, wrtLen1=15, wrtLen2=43, subsPerProc=1).\n",
      "  Finding num_nongauge_params is too expensive: using total params.\n",
      "  Sum of Chi^2 = 1656.75 (1585 data params - 43 model params = expected mean of 1542; p-value = 0.0212197)\n",
      "  Completed in 0.3s\n",
      "  2*Delta(log(L)) = 1658.05\n",
      "  Iteration 6 took 0.4s\n",
      "  \n",
      "  Switching to ML objective (last iteration)\n",
      "  --- MLGST ---\n",
      "  Memory: limit = 2.10GB(cur, persist, gthr = 0.12, 0.00, 0.21 GB)\n",
      "  Evaltree generation (deriv) w/mem limit = 1.77GB\n",
      "   mem(1 subtrees, 3,1 param-grps, 1 proc-grps) in 0s = 0.00GB (0.00GB fc)\n",
      "  Created evaluation tree with 1 subtrees.  Will divide 3 procs into 1 (subtree-processing)\n",
      "   groups of ~3 procs each, to distribute over 43 params (taken as 3 param groups of ~14 params).\n",
      "   Memory estimate = 0.00GB (cache=1810, wrtLen1=15, wrtLen2=43, subsPerProc=1).\n",
      "  Finding num_nongauge_params is too expensive: using total params.\n",
      "    Maximum log(L) = 828.989 below upper bound of -2.65043e+06\n",
      "      2*Delta(log(L)) = 1657.98 (1585 data params - 43 model params = expected mean of 1542; p-value = 0.0201737)\n",
      "    Completed in 0.6s\n",
      "  2*Delta(log(L)) = 1657.98\n",
      "  Final MLGST took 0.6s\n",
      "  \n",
      "Iterative MLGST Total Time: 1.8s\n",
      "Rank 0 finished in 5.0s\n",
      "Rank 2 finished in 5.0s\n",
      "Rank 1 finished in 5.0s\n"
     ]
    }
   ],
   "source": [
    "! mpiexec -n 3 python3 \"example_files/mpi_example_script.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Notice in the above that output within `do_long_sequence_gst` is not duplicated (only the first processor outputs to stdout) so that the output looks identical to running on a single processor.  Finally, we just need to read the pickled `Results` object from file and proceed with any post-processing analysis.  In this case, we'll just create a  report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Creating workspace ***\n",
      "*** Generating switchboard tables ***\n",
      "  targetSpamBriefTable                          took 0.001083 seconds\n",
      "  targetGatesBoxTable                           took 0.015872 seconds\n",
      "  datasetOverviewTable                          took 0.017869 seconds\n",
      "  bestGatesetSpamParametersTable                took 0.00075 seconds\n",
      "  bestGatesetSpamBriefTable                     took 0.001513 seconds\n",
      "  bestGatesetSpamVsTargetTable                  took 0.002936 seconds\n",
      "  bestGatesetGaugeOptParamsTable                took 0.000287 seconds\n",
      "  bestGatesetGatesBoxTable                      took 0.0155 seconds\n",
      "  bestGatesetChoiEvalTable                      took 0.007951 seconds\n",
      "  bestGatesetDecompTable                        took 0.008052 seconds\n",
      "  bestGatesetEvalTable                          took 0.007688 seconds\n",
      "  bestGatesetRelEvalTable                       took 0.000849 seconds\n",
      "  bestGatesetVsTargetTable                      took 0.44825 seconds\n",
      "  bestGatesVsTargetTable                        took 0.124029 seconds\n",
      "  bestGatesVsTargetTable_sum                    took 0.000206 seconds\n",
      "  bestGatesetErrGenBoxTable                     took 0.064364 seconds\n",
      "  metadataTable                                 took 0.000949 seconds\n",
      "  softwareEnvTable                              took 0.031563 seconds\n",
      "  fiducialListTable                             took 0.000541 seconds\n",
      "  prepStrListTable                              took 0.000167 seconds\n",
      "  effectStrListTable                            took 0.000152 seconds\n",
      "  germList2ColTable                             took 0.000275 seconds\n",
      "  progressTable                                 took 0.361338 seconds\n",
      "*** Generating plots ***\n",
      "  gramBarPlot                                   took 0.010533 seconds\n",
      "  progressBarPlot                               took 0.099483 seconds\n",
      "  dataScalingColorBoxPlot                       took 0.06024 seconds\n",
      "  bestEstimateColorBoxPlotPages                 took 0.867407 seconds\n",
      "  bestEstimateColorScatterPlot                  took 2.12197 seconds\n",
      "*** Merging into template file ***\n",
      "Output written to example_files/mpi_example_brief.html\n",
      "Opening example_files/mpi_example_brief.html...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pygsti.report.workspace.Workspace at 0x10bf12dd8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "results = pickle.load(open(\"example_files/mpi_example_results.pkl\",\"rb\"))\n",
    "pygsti.report.create_general_report(results, \"example_files/mpi_example_brief.html\",\n",
    "                                    title=\"MPI Example Report\", verbosity=2, auto_open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
