{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mirror Randomized Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial contains a few details on how to run *Mirror Randomized Benchmarking* that are not covered in the [RB overview tutorial](RB-Overview.ipynb).\n",
    "\n",
    "## What is Mirect RB? \n",
    "\n",
    "Like Direct RB, Mirror RB is a streamlined RB method partly inspired by [Clifford RB](RB-CliffordRB.ipynb). It has the same core purpose as Clifford RB - quantifying average gate performance - but it is feasable on more qubits, and it provides more directly useful information. However, Mirror RB is even more streamlined than Direct RB, making it feasable on 10s or 100s of qubits (it is possible to holistically benchmark around $1/\\epsilon$ qubits if the error rate per-gate per-qubit is around $\\epsilon$).\n",
    "\n",
    "Mirror RB can be implemented with non-Clifford gates, but pyGSTi currently only contains Mirror RB for Clifford gates. A depth $m$ ($m\\geq 0$) mirror RB circuit consists of:\n",
    "\n",
    "1. A uniformly random 1-qubit Clifford gate on every qubit. \n",
    "2. A \"compute\" circuit consisting of $m/2$ independently sampled layers of the native Clifford gates in the device, sampled according to a user-specified distribution $\\Omega$. Each of these layers is proceeded by a uniformly random Pauli gate on each qubit.\n",
    "3. A layer of uniformly random Pauli gates.\n",
    "4. An \"uncompute\" circuit consisting of the $m/2$ layers from step (2) in the reverse order with each gate replaced with its inverse. Each of these layers is followed by a uniformly random Pauli gate on each qubit, with these Pauli gates sampled *independently* of the Pauli layers in step (2).\n",
    "5. The inverse of the random 1-qubit Clifford gates in step (1).\n",
    "\n",
    "This construction means that Mirror RB circuits can be much shorter than Clifford RB circuits, or Direct RB circuits. Yet they still have the core randomization properties of both Clifford and Direct RB.\n",
    "\n",
    "**More information on Mirror RB will be added to this tutorial in a future release.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function #python 2 & 3 compatibility\n",
    "import pygsti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Mirror RB experiment design\n",
    "\n",
    "Generating a Mirror RB experiment design is very similar to creating a Direct RB design. The only difference is that there is no compilation in a Mirror RB circuit, so there is no compilation algorithm to tweak.\n",
    "\n",
    "### 1. Generic RB inputs\n",
    "\n",
    "The first inputs to create a Mirror RB experiment design are the same as in all RB protocols, and these are covered in the [RB overview tutorial](RB-Overview.ipynb). They are:\n",
    "\n",
    "- The device to benchmark (`pspec`).\n",
    "- The \"RB depths\" at which we will sample circuits (`depths`). For Mirror RB, these depths must be even integers. They correspond to the number of total layers in the \"compute\" and \"uncompute\" sub-circuits (but where we don't include the randomized Pauli gates in the layer count). \n",
    "- The number of circuits to sample at each length (`k`).\n",
    "- The qubits to benchmark (`qubits`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mirror RB can be run on many many more qubit than this, but this notebook creates simulated data. As \n",
    "# we are using a full density matrix simulator this limits the number of qubits we can use here.\n",
    "nQubits = 4\n",
    "qubit_labels = ['Q'+str(i) for i in range(nQubits)] \n",
    "gate_names = ['Gi', 'Gxpi2', 'Gxpi', 'Gxmpi2', 'Gypi2', 'Gypi', 'Gympi2', \n",
    "              'Gzpi2', 'Gzpi', 'Gzmpi2', 'Gcphase'] \n",
    "availability = {'Gcphase':[('Q'+str(i),'Q'+str((i+1) % nQubits)) for i in range(nQubits)]}\n",
    "pspec = pygsti.obj.ProcessorSpec(nQubits, gate_names, availability=availability,\n",
    "                                 construct_clifford_compilations={'absolute': ('paulis', '1Qcliffords')},\n",
    "                                 qubit_labels=qubit_labels, construct_models=('clifford',))\n",
    "\n",
    "depths = [0, 2, 4, 8, 16, 32]\n",
    "k = 40\n",
    "qubits = qubit_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All other arguments to the Mirect RB experiment design generation function `MirectRBDesign` are optional. But, as with Direct RB, to make the most out of Mirect RB it is typically important to at least understand the circuit layer sampling.\n",
    "\n",
    "### 2. The circuit layer sampler\n",
    "Exactly as with Direct RB, the Mirect RB circuit layer sampling distribution $\\Omega$ is perhaps the most important input to the Mirect RB experiment design. This is because, by construction, the Mirect RB error rate $r$ is $\\Omega$-dependent. This $\\Omega$-dependence is useful, because by carefully choosing or varying $\\Omega$ we can learn a lot about device performance. But it also means that the $\\Omega$ has to be carefully chosen! At the very least, **you need to know what sampling distribution you are using in order to interpret the results!**\n",
    "\n",
    "This might seem like a drawback in comparison to Clifford RB, but note that this $\\Omega$-dependence is analogous to the Clifford-compiler dependence of the Clifford RB error rate (with the advantage that it is more easily controlled and understood). And Mirror RB can be run on many, many more qubits!\n",
    "\n",
    "The sampling distribution is specified via the optional arguements `sampler` and `samplerargs`. Here we use what we call the \"edge grab\" sampler. \n",
    "\n",
    "Because both Direct and Mirror RB have the this sampling-distribution dependence, there is a separate [random circuit sampling tutorial](RB-Samplers.ipynb) that introduces the different built-in sampling algorithms within pyGSTi (which includes details of the \"edge grab\" algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = 'edgegrab'\n",
    "samplerargs = [0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, generating the design and collecting data proceeds as in the RB overview tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we construct an error model with 5% local depolarization on each qubit after each gate.\n",
    "gate_error_rate = 0.02\n",
    "def simulate_taking_data(data_template_filename):\n",
    "    \"\"\"Simulate taking data and filling the results into a template dataset.txt file\"\"\"\n",
    "    pspec = pygsti.obj.ProcessorSpec(nQubits, gate_names, availability=availability, \n",
    "                                     qubit_labels=qubit_labels, construct_models=('TP',))\n",
    "    noisemodel = pspec.models['TP'].copy()\n",
    "    for gate in noisemodel.operation_blks['gates'].values():\n",
    "        if gate.dim == 16:\n",
    "            gate.depolarize(1 - pygsti.tools.rbtools.r_to_p(1 - (1-gate_error_rate)**2, 4))\n",
    "        if gate.dim == 4:\n",
    "            gate.depolarize(1 - pygsti.tools.rbtools.r_to_p(gate_error_rate, 2))\n",
    "    pygsti.io.fill_in_empty_dataset_with_fake_data(noisemodel, data_template_filename, nSamples=1000, seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "design = pygsti.protocols.MirrorRBDesign(pspec, depths, k, qubit_labels=qubits, sampler=sampler, \n",
    "                                        samplerargs=samplerargs)\n",
    "\n",
    "pygsti.io.write_empty_protocol_data(design, '../tutorial_files/test_rb_dir', clobber_ok=True)\n",
    "\n",
    "# -- fill in the dataset file in tutorial_files/test_rb_dir/data/dataset.txt --\n",
    "simulate_taking_data('../tutorial_files/test_rb_dir/data/dataset.txt') # REPLACE with actual data-taking\n",
    "\n",
    "data = pygsti.io.load_data_from_dir('../tutorial_files/test_rb_dir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Mirror RB protocol\n",
    "As with all RB methods in pyGSTi, to analyze the data we instantiate an `RB` protocol and `.run` it on our data object.  However, there is a slight difference for Mirror RB. Mirror RB doesn't fit simple success/fail format data: instead it fits what we call *Hamming weight adjusted success probabilities* to an exponential decay ($P_m = A + B p^m$ where $P_m$ is the average adjusted success probability at RB length $m$). \n",
    "\n",
    "To obtain this data analysis we simply specify the data type when instantiate an `RB` protocol: we set `datatype = adjusted_success_probabilities`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol = pygsti.protocols.RB(datatype = 'adjusted_success_probabilities', defaultfit='A-fixed')\n",
    "results = protocol.run(data)\n",
    "ws = pygsti.report.Workspace()\n",
    "ws.init_notebook_mode(autodisplay=True)\n",
    "ws.RandomizedBenchmarkingPlot(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The error rate we *approximately* expect accord to Mirror RB theory\n",
    "print(1 - (1 - gate_error_rate)**(2 * len(qubits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
