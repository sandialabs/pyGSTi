<!DOCTYPE html>
<html>
  <head>
    <title>%(title)s</title>
    <meta charset="UTF-8" />

    %(favicon)s
    
    %(jqueryLIB)s
    %(jqueryUILIB)s
    %(plotlyLIB)s
    %(plotlyexLIB)s
    %(katexLIB)s
    <!-- XXX(mathjaxLIB)s -->

    %(CSS)s
  </head>
  
  <body>

    <header class="counter-skip">
      <h1 class="title">%(title)s</h1>
      <h2>generated by pyGSTi on %(date)s</h2>
    </header>

    <div class="abstract counter-skip">
      <h1>Abstract</h1>
      <p>This report presents a gate-set tomography (GST) analysis of a dataset called %(datasetLabel)s.</p>
    </div>
    
    
    <h1>Overview</h1>
    <section>
      <p>GST characterizes logic operations on a quantum device (e.g., a qubit), by treating it as a black box. This black box is equipped with a small set of “buttons” that apply quantum <em>gates</em> to the quantum system inside. One button initializes it, a second button triggers a 2-outcome measurement, and the remaining buttons perform transformations. We avoid assumptions about the device&apos;s operation whenever possible. Currently, we assume that: </p>

      <ul>
       <li>the quantum device is a qubit (has a Hilbert space of dimension 2),</li>
       <li>each <em>gate</em>, or logic operation, can be represented by a stationary Markov process (a.k.a. “quantum channel”).</li>
      </ul>

      <p>The core of GST is an algorithm that takes certain inputs, and produces certain outputs. The <em>input</em> to GST comprises (1) a list of data, and (2) “target” gate set describing the <em>ideal</em> behavior of the device. GST data comprises a list of experiments – each described by the sequence of gates that was applied – and, for each experiment, two integer <em>counts</em> stating how often the “plus” and “minus” results were observed. The target gates are used <em>only</em> to (a) report how consistent the estimates are with the target, and (b) choose the best <em>gauge</em> in which to report the results. GST does not take them into account in its core analysis, and there is no possibility of circularity or other <q>cheating</q>.</p>

      <p>GST&apos;s primary output is an estimated <em>gate set</em> that models or ﬁts the device&apos;s observed behavior. Gate sets are of the form $\{\rho_0,E_0,\{G_k\}\}$, where</p>
      <ul>
	<li> $\rho_0$ is an estimate of the density matrix in which the device gets initialized,</li>
	<li> $\{E_0,1\!\mathrm{l}-E_0\}$ is an estimate of the POVM describing how it gets measured, </li>
	<li> and each of the $G_k$ is an estimate of the superoperator (quantum process) describing the corresponding gate.</li>
      </ul>
      
    <p>Unless something went wrong (usually it doesn&apos;t), the output of GST is the best possible ﬁt to the data. This should also mean that the output is a very accurate description of what happens when you trigger a gate on your device. However, this happy conclusion relies on two assumptions:
    </p>

    <ol>
      <li>The experiments were chosen wisely, so that the only gate sets consistent with their results are very close to the true behavior. This is usually true. The main failure mode occurs when you were not able to perform <em>long</em> sequences (e.g., because your decoherence rate is very high), in which case accuracy may be limited. </li>
      <li>The operations you are performing really are stationary (time-independent), Markovian, and acting on a quantum system with the correct Hilbert space dimension. These assumptions deﬁne the <em>model</em> that GST ﬁts to the data. <strong>They are usually not true!</strong> Quantum operations are usually at least a little bit non-Markovian. In this report (<a href="#secGoodness" class="section"></a>) we provide extensive self-checks to identify and diagnose violations of the model. If your system <em>is</em> visibly non-Markovian, then (a) these checks will probably warn you of it, and (b) the other quantities reported here should be treated with caution – using GST on non-Markovian gates violates the warranty!</li>
    </ol>
    </section>

    <section id="secInput">
    <h1>Input Summary</h1>
    <p>The input for this GST analysis comprised: (1) a target gate set and (2) a dataset called %(datasetLabel)s.</p>
    %(topSwitchboard)s

    <h2>Target Gate set</h2>
    <p>The target gate set describes the ideal initial state (density matrix), measurement (POVM eﬀect), and gate operations (superoperators). Typically, density matrices and POVM eﬀects are represented as square $d\times d$ matrices on a Hilbert space $\mathcal{H}$.  In GST, it is often more convenient to represent them as $d^2$-element vectors in the Hilbert-Schmidt space $\mathcal{B}(\mathcal{H})$ of linear operators on $\mathcal{H}$.  Both representations are shown in <a href="#targetGatesetTable" class="table"></a>.  Superoperators are sometimes represented in Choi or Kraus form, but for GST it is more convenient to represent them as square $d^2\times d^2$ matrices that multiply associatively and act on $\mathcal{B}(\mathcal{H})$.  These are shown in Table <a href="#targetGatesBoxTable" class="table"></a>.</p>

    <p>These Hilbert-Schmidt space representations require choosing a basis $\{M_i\}$ for $\mathcal{B}(\mathcal{H})$.  We use the <em>Pauli basis</em>, comprising the four $2\times2$ Pauli matrices (including the identity $1\!\mathrm{l}$) for $d=2$.  In $d>2$, we use the analogous Gell-Mann matrices as a basis.   The choice of this basis is what is meant when state preparations and measurements are written as vectors and gate operations are written as matrices in the <q>Pauli basis</q>.  Keep in mind that we want to use an orthonormal basis, so the basis matrices are normalized so that $\left\langle \left\langle M_i | M_j \right\rangle \right\rangle = \mathrm{Tr} M_i^\dagger M_j = \delta_{ij}$.  In $d=2$, this means that the basis matrices are $M_i = \frac{1}{\sqrt{2}}\sigma_i$.</p>

    <figure id='targetGatesetTable' class='tbl'>
      <figcaption><strong>Target gate set: SPAM (state preparation and measurement) and logic gates</strong>.  The <strong>left</strong> table shows the <em>ideal</em> input state ($\rho_0$) and `plus' POVM effect $E_0$ for the device on which we report.  SPAM gates are given here as $d\times d$ matrices.  The <strong>right</strong> table shows the <em>ideal</em> (generally unitary) logic gates.  Each has a name starting with <q>G</q>, and is represented as a $d^2\times d^2$ <em>superoperator</em> that acts by matrix multiplication on vectors in $\mathcal{B}(\mathcal{H})$.  Matrices are displayed using a heat map that ranges between 1.0 (red) and -1.0 (blue).</figcaption>
      %(targetSpamBriefTable)s
    </figure>

    <h2>GST Input Data</h2>
    <p>The most important input to GST is a <em>dataset</em> -- a list of experimental counts or frequencies, each associated with a <em>gate sequences</em>.  Gate sequences are also referred to as <q>gate strings</q>.  Each gate sequence defines an experiment, in which you (1) initialize the device, (2) apply the operations specified by the gate sequence, and (3) measure and record the result (<q>plus</q> or <q>minus</q>).</p>
    
    <p>Typically, the gate sequences that appear in the dataset are generated by the following process:</p>
    <ol>
      <li>A small set of short gate sequences called <em>germs</em> are chosen,</li>
      <li>A small set of short <em>fiducial sequences</em> are chosen so that, when applied to $\rho_0$ or $E_0$, they generate an informationally complete set of states or effects.</li>
      <li>Each germ is concatenated with itself to form <em>base sequences</em> of length approximately $1,2,4,8,\ldots L_{max}$.</li>
      <li>Each base sequence is sandwiched between every possible pair of fiducial sequences.</li>
    </ol>
    <p>The dataset comprises all sandwiched base sequences.  A few other short sequences (e.g., those corresponding to the empty base sequence) may also appear.</p>

    <!--\iftoggle{LsAndGermsSet}{-->
    <p>The fiducial sequences and germs for <em>this</em> dataset are given in Table <a href="#fiducialAndGermListTables" class="table"></a>. An overview of the information contained in the file you provided for dataset <q>%(datasetLabel)s</q> is given in Table <a href="#datasetOverviewTable" class="table"></a>.</p>
    <!--}{ Fiducial sequence and germ information was not given for this report, and may not be applicable.}-->

    <p> This table also contains one derived quantity, the spectrum of the largest <em>Gram matrix</em> that GST could extract from the data.  This is included here rather than in the analysis because it is not useful for predictive purposes, and therefore is not part of the estimate.  It serves, instead, to tell you something about the quality of the data.  More precisely, it tells you about the dimension of the state space that is explored by the fiducial sequences.  This should be $d^2$-dimensional [because the fiducials are intended to explore all of $\mathcal{B}(\mathcal{H})$], and therefore the spectrum listed in Table <a href="#datasetOverviewTable" class="table"></a> should (ideally) have exactly $d^2$ elements that are large and nonzero.  In practice, you should see $d^2$ large elements, and a rapid drop in magnitude thereafter.  If fewer than $d^2$ elements are large, then the fiducials were poorly chosen and are not exploring the state space effectively.  If more than $d^2$ are large, then the system is experiencing strong non-Markovian effects (e.g., strong coupling to environmental degrees of freedom) or it has a larger Hilbert space dimension than expected.</p>

    <figure id="fiducialListTable" class='tbl'>
      <figcaption><strong>Fiducial sequences</strong>.  A list of the preparation and measurement <q>fiducial</q> gate sequences. See discussion in text.</figcaption>
      %(fiducialListTable)s
    </figure>

    <figure id="germListTable" class='tbl'>
      <figcaption><strong>Germ sequences</strong>.  A list of the <q>germ</q> gate sequences.  See discussion in text.</figcaption>
      %(germList2ColTable)s
    </figure>

    <figure id="datasetOverviewTable" class='tbl'>
      <figcaption><strong>General dataset properties</strong>.  See discussion in text.</figcaption>
      %(datasetOverviewTable)s
    </figure>

    <section id="secOutput">
    <h1>Output from GST</h1>
    <p>The primary output of GST is an estimated gate set.  This section presents the raw estimate, and then some useful derived quantities of the estimated gates, including comparisons to the target gates.  Some of these quanties are <q>gauge-dependent</q>, meaning they will depend on unphysical gauge degrees of freedom that are a necessary byproduct of estimating an entire gate set at once (akin to a freedom of reference frame).  After finding a best-estimate based on the (physical) data, GST optimizes within the space of all (unphysical) gauge degrees of freedom.  Typically this is done to make the estimated gates and SPAM operations look as close to the ideal target gates as possible.  But tradeoffs can and almost always must be made regarding this optimization.  Table <a href="#bestGatesetGaugeParamsTable" class="table"></a> lists the relevant parameters used during the gauge optimization step which resulted in the estimates that follow.</p>

    <figure id="bestGatesetGaugeParamsTable" class='tbl'>
      <figcaption><strong>Gauge Optimization Details</strong>.  A list of the parameters used when performing the gauge optimization that produced the final GST results found in subsequent tables and figures.</figcaption>
      %(bestGatesetGaugeOptParamsTable)s
      %(goSwitchboard1)s
    </figure>

    <h2>Raw GST estimates</h2>
    <p>Table <a href="#bestGatesetSpamTable" class="table"></a> reports the estimated SPAM operations, and Table <a href="#bestGatesetGatesTable" class="table"></a> reports the logic gate operations.  The estimated SPAM gates ($\rho_0$ and $E_0$) are vectors in $\mathcal{B}(\mathcal{H})$, and the estimated logic gates are superoperators represented as matrices acting on $\mathcal{B}(\mathcal{H})$, all in the Pauli basis.   By taking the dot product of state preparation and measurement vectors, estimated SPAM probabilites are computed in Table <a href="#bestGatesetSpamParametersTable" class="table"></a>.

      <!--\iftoggle{confidences}{
      <p>Tables <a href="#bestGatesetSpamTable" class="table"></a> and <a href="#bestGatesetGatesTable" class="table"></a> report %(confidenceLevel)s%% confidence intervals for each of the gate matrix and SPAM vector elements.  A confidence region is obtained by approximating the log-likelihood (see below) as being quadratic about its minimum, and determining the ellipsoid where this approximation equals a value, $C$, defined below.  For a given parameter (e.g. gate or SPAM vector element) $x$, a confidence interval is obtained by projecting the ellipsiodal region onto that $x$'s axis.  This computes a 1-dimensional %(confidenceLevel)s%% confidence interval for the profile log-liklihood for $x$, and for this reason the value of $C$ used above is chosen such that $\mathrm{CDF}[\chi^2_1](C) = %(confidenceLevel)s\\%%$ (that is, at the value $C$ the cumulative density function of a $\chi^2_1$ distribution reaches %(confidenceLevel)s%%).  If, instead, the interval corresponding to a projection of the %(confidenceLevel)s%% multi-dimensional confidence region (defined by $C$ s.t.~$\mathrm{CDF}[\chi^2_n](C) = %(confidenceLevel)s\\%%$, where $n=%(confidenceIntervalNumNonGaugeParams)s$ is the number of non-gauge gate set parameters) is desired, then the all the interval widths reported here should be multiplied by %(confidenceIntervalScaleFctr)s.  The resulting confidence interval is always symmetric about the estimated value, and we report the half-width of the intervals in the tables.  In table <a href="#bestGatesetSpamParametersTable" class="table"></a> and those in the following section, we specify the %(confidenceLevel)s%% confidence intervals of derived quantities in using <em>value</em> $\pm$ <em>half-width</em> notation.  The derived-quantity confidence intervals in section <a href="#derivedQtySection" class="section"></a> are computed by finding the minimum and maximum values of the linearization of the derived quantity (e.g.~fidelity).</p> -->

      <figure id="bestGatesetSpamTable" class='tbl'>
	<figcaption><strong>The GST estimate of the SPAM operations</strong>.  Compares the estimated SPAM operations to those desired (repeated from Table <a href="#targetGatesetTable"></a> for convenience.</figcaption>
	%(bestGatesetSpamBriefTable)s
      </figure>
      
      <figure id="bestGatesetSpamParametersTable" class='tbl'>
	<figcaption><strong>GST estimate of SPAM probabilities</strong>.  Computed by taking the dot products of vectors in Table <a href="#bestGatesetSpamTable" class="table"></a>.  The symbol $E_C$, when it appears, refers to the <q>complement</q> effect given by subtracting each of the other effects from the identity.</figcaption>
	%(bestGatesetSpamParametersTable)s
      </figure>

      <figure id="bestGatesetGatesTable" class='tbl'>
	<figcaption><strong>The GST estimate of the logic gate operations</strong>.  Compares the <em>ideal</em> (generally unitary) logic gates (second column, also in Table <a href="#targetGatesetTable" class="table"></a>) with those <em>estimated</em> by GST (third column).  Each gate is represented as a $d^2\times d^2$ <em>superoperator</em> that acts by matrix multiplication on vectors in $\mathcal{B}(\mathcal{H})$.  Matrices are displayed using a heat map that ranges between 1.0 (red) and -1.0 (blue).  Note that it is impossible to discern even order-1%% deviations from the ideal using this color scale, and one should rely on other analysis for more a precise comparison.</figcaption>
	%(bestGatesetGatesBoxTable)s
      </figure>

    <h2 id="derivedQtySection">Derived quantities</h2>
    <p>Generally, the first thing that you want to know is <q>How far from ideal are the gates?</q>.  To answer this, the report tabulates several well-known definitions of distance.  Table <a href="#bestGatesetVsTargetTable" class="table"></a> lists the discrepancy from each estimated gate to its corresponding target, as measured by:</p>
    <ol>
      <li><strong>Process infidelity</strong>.  Infidelity is simply $1-F$, where $F$ is the <em>fidelity</em>.  The process fidelity between quantum processes $G_a$ and $G_b$ is given by $F = \mathrm{Tr}\left( \sqrt{ \sqrt{\chi_a} \chi_b \sqrt{\chi_a} } \right)^2$, where $\chi_a$ and $\chi_b$ are the Jamiolkowski states (normalized Choi process matrices) corresponding to gate matrices $G_a$ and $G_b$ respectively.  If the target is unitary (as is often the case), $F = \mathrm{Tr}\left( \chi_a \chi_b \right)$.  Process infidelity is roughly what is measured in randomized benchmarking protocols; it quantifies the <em>incoherent</em> error rate if coherent errors (e.g. over-rotations) are not allowed to accumulate.</li>
      <li><strong>Trace distance</strong>.  This is the <em>Jamiolkowski trace distance</em> between the Jamiolkowski states corresponding to the two processes:  $d_{tr} = \vert\chi_a - \chi_b\vert_1 = \mathrm{Tr}\left(\sqrt{(\chi_a-\chi_b)^2}\right)$.  This distance is useful primarily as a proxy for the <em>diamond norm distance</em>, because $d_{tr} \leq d_{\diamond} \leq \mathrm{dim}(\mathcal{H}) d_{tr}$.</li>
      <li><strong>Diamond Norm</strong>.  The diamond norm between two quantum processes $G_a$ and $G_b$ is given by $\left\lVert G_a - G_b \right\rVert_\Diamond = \sup_\rho \left\lVert(G_a \otimes I_k)(\rho) - (G_b \otimes I_k)(\rho) \right\rVert_1$, where $I_k$ is the $k$-dimensional identity operation, $\left\lVert\cdot\right\rVert_1$ denotes the trace norm, and the supremum is taken over all $k \ge 1$ and density matrices $\rho$ of dimension $nk$, with $n$ the dimension of $G_a$ and $G_b$.  The diamond norm is also called the <em>completely bounded trace norm</em>, and plays the analogous role for quantum process distinguishability that the trace norm plays for density matrices.  Specifically, the optimal probability of distinguishing $G_a$ from $G_b$ after a <em>single evaluation</em> is given by $\frac{1}{2} + \frac{1}{4}\left\lVert G_a - G_b \right\rVert_\Diamond$.  The diamond norm distance is an upper bound on the rate of error under any possible circumstance (including coherent accumulation of errors) and is often used in proofs of fault tolerance.  For gates dominated by coherent/unitary error, it is common to see $d_{\diamond} \approx \sqrt{1-F}$.  For gates dominated by incoherent error, $d_{\diamond} \approx 1-F$.</li>
      <li><strong>Frobenius-norm distance</strong>.  The Frobenius norm distance between two gates $G_a$ and $G_b$ is simply $d_F = \sqrt{\mathrm{Tr}\left[\left(G_a-G_b\right)^2\right]}$.  It has no known <em>operational</em> interpretation, but is very convenient as a rough measure of inaccuracy.  It is also equal to the sum of the RMS errors in the individual matrix elements of the gates.</li>
    </ol>

    <p>It's also useful to know <em>how</em> the real gates (or, more precisely, GST's estimates of the real gates) differ from the targets.  There are several ways we could represent this, but the most useful involves an <em>error generator</em>.  These are also given in Table <a href="#bestGatesetVsTargetTable" class="table"></a>.  The final column of the table lists, for each gate, a Lindbladian superoperator $\mathbb{L}$.  It is defined by the equation %(errorgenformula)s, where $\hat{G}$ is the estimate and $G_{\mathrm{target}}$ is the ideal gate.  This Lindbladian would be zero if the gates were perfect, and its overall magnitude is approximately equal to the diamond distance (or Jamiolkowski trace distance) between the target gate and the estimate.</p>

    <figure id="bestGatesetVsTargetTable" class='tbl'>
      <figcaption><strong>Comparison of GST estimated gates to target gates</strong>.  This table presents, for each of the gates, three different measures of distance or discrepancy from the GST estimate to the ideal target operation.  See text for more detail.</figcaption>
      %(bestGatesetVsTargetTable)s
      %(goSwitchboard2)s
    </figure>

    <figure id="bestGatesetSpamVsTargetTable" class='tbl'>
      <figcaption><strong>Comparison of GST estimated SPAM to target SPAM</strong>.  This table presents, for each state preparation and POVM effect, two different measures of distance or discrepancy from the GST estimate to the ideal target operation.  See text for more detail.</figcaption>
      %(bestGatesetSpamVsTargetTable)s
    </figure>

    <figure id="bestGatesetErrGenTable" class='tbl'>
      <figcaption><strong>The GST estimate of the logic gate operation generators</strong>. A heat map of the <q>Error Generator</q> for each gate, which is the Lindbladian $\mathbb{L}$ that describes <em>how</em> the gate is failing to match the target.  This error generator is defined by the equation %(errorgenformula)s. When all elements of these matrices is zero, the estimated gates match the target gates (Table <a href="#targetGatesetTable" class="table"></a>).  Note that the range of the color scale is variable, being determined by the data.  In the third column, each generator is projected onto each of the <q>Hamiltonian generators</q> given by the action of commutation with each Pauli-product basis element.  In the forth column, each generator is projected onto each of the <q>Stochastic generators</q> given by the action of conjugation with each Pauli-product basis element.  Columns and rows correspond to Pauli operators on the first and second (if present) qubit.</figcaption>
      %(bestGatesetErrGenBoxTable)s
    </figure>

    <p>It's usually useful to understand <em>how</em> gates fail.  The error generators in Table <a href="#bestGatesetErrGenTable" class="table"></a> provide one view on this, but they are not necessarily intuitive.   For example, you might want to know whether your gate suffers depolarizing, dephasing, or over-rotation errors.  In Tables <a href="#bestGatesetEigenvalueTable" class="table"></a>, the eigenvalues of the estimated gates are shown and plotted on the complex disc (which can be helpful for visualizing the different types of errors, e.g., over- or under-rotation vs.~depolarization).</p>
    <!--
Table <a href="#bestGatesetRelativeEigenvalueTable" class="table"></a> shows the same quantities but for the eigenvalues of %(errorgenformula)s, which would all be $1.0$ if the gate were ideal.
 Table <a href="#bestGatesetPolarEigvalTable" class="table"></a> plots these eigenvalues on the complex disc, which can be helpful for visualizing the different types of errors (e.g.~over- or under-rotation vs.~depolarization). -->
    <!-- TODO: add hamiltonian generator projections figure? -->

    <figure id="bestGatesetEigenvalueTable" class='tbl'>
      <figcaption><strong>Eigenvalues of estimated gates</strong>.  The spectrum (Eigenvalues column) of each estimated gate.  The second column displays these eigenvalues over the complex disc.</figcaption>
      %(bestGatesetEvalTable)s
      %(goSwitchboard3)s
    </figure>

    <p>Finally, Table <a href="#bestGatesetChoiTable" class="table"></a> presents each estimated gate's <em>Choi matrix</em>, along with its spectrum.  The Choi matrix (sometimes ambiguously referred to as the <q>process matrix</q>) is an alternative way to describe a process.  We usually prefer the <q>superoperator representation</q>, which has the very useful property that the process matrix corresponding to applying $G_a$ and then $G_b$ is simply $G_bG_a$.  This is completely false for the Choi representation.  Nonetheless, the Choi representation is often useful, so we present it here -- but without a detailed discussion of its properties (see, e.g. the textbook by Nielsen and Chuang).</p>

     <p>The Choi matrix $\chi(G)$ for a gate $G$ can be simply understood in either of two ways.  First, it is equivalent (up to choice of basis) to the <em>Jamiolkowski state</em> defined by applying $G$ to one half of a maximally entangled bipartite state.  Second, it is the general (non-diagonal) form of the well-known Kraus representation, $G[\rho] = \sum_i{K_i\rho K_i^\dagger}$.  The Choi matrix behaves in many ways like a quantum state, and appears naturally in expressions for the process fidelity and Jamiolkowsi trace distance just as density matrices would enter these expressions when computing differences between states.</p>

    <p>Additionally, the condition of <em>complete positivity</em> or CP (which all real quantum processes must satisfy) is simply the positivity of the Choi matrix.  Thus, negative eigenvalues in Table <a href="#bestGatesetChoiTable" class="table"></a> indicate that the estimate violates complete positivity.  If they are very small, they may simply indicate statistical fluctuations (unitary gates have $\chi$ matrices with zero eigenvalues, so any small fluctuation is likely to violate CP).  If they are large, they serve as a warning that (1) the model of CPTP maps is probably violated (usually because of non-Markovian behavior), and (2) this estimate may produce negative or greater-than-unity probabilities.  GST does <em>not</em> generally impose complete positivity (although it is an option), precisely because violation of CP is a warning flag for non-Markovian behavior (which is very common in experimental qubits).</p>

    <figure id="bestGatesetChoiTable" class='tbl'>
      <figcaption><strong>Choi matrix spectrum of the GST estimated gate set</strong>.  The eigenvalues of the Choi representation of each estimated gate.  In the third column, magnitudes of <em>negative</em> values are plotted using \textcolor{red}{red} bars. Unitary gates have a spectrum $(1,0,0\ldots)$, just like pure quantum states.  Negative eigenvalues are non-physical, and may represent either statistical fluctuations or violations of the CPTP model used by GST.</figcaption>
      %(bestGatesetChoiEvalTable)s
      %(goSwitchboard4)s
    </figure>

    </section>
    
    <section id="secGoodness">
    <h1>Goodness-of-model Analysis</h1>
    <p>The previous section presented the estimated gate set, and compared it to the target gate set.  This section is concerned with a mostly orthogonal analysis which seeks to explain how much the estimated gate set can be trusted -- i.e., how well it fits the data.</p>

    <p>To understand the goal of this section, consider the simple problem of fitting a line to a set of points.  For any set of points, there is <em>always</em> a best-fit line -- but this doesn't mean that the best-fit line is a <em>good</em> fit!  The data points may trace out a parabola, a square, or even something more complicated.  It is essential to understand not just what the best-fit line was (and perhaps how close it was to some desired line), but also <strong>how well that linear model was able to fit all the data</strong>.  Of course, we do not expect it to fit every data point perfectly.  The critical question is <q>Did the linear model fit <em>as well as we would expect it to</em> if the data really were generated by a linear process?</q></p>

    <p>In this analogy, GST's estimated gate set is like the best-fit line, and the target gate set like the desired line.  This section asks the question <q>How well was GST able to fit all of the data -- and did it fit well enough to suggest that its model is valid?</q>. A central tool used to do this is the <em>likelihood function</em>, which we denote $\mathcal{L}$, which formally is the probability of the observed data given a set of model parameters.  The basic idea is that we maximize the likelihood function to obtain the best set of model parameters (i.e.~gate set), and by looking at the value of this maximum we can determine the model's goodness-of-fit.  We will actually deal primarily with the logarithm of the likelihood function, $\log(\mathcal{L})$, which is simliarly maximized.</p>

    <h2>Aggregated logL</h2>
    <p>The log-likelihood for an $n$-outcome system with predicted probabilities $p_i$ and observed frequencies $f_i$ ($i=1\ldots n$) is given by:</p>

    <div class="equation">
      $$ \log(\mathcal{L}) = \sum_i N f_i \log(p_i). $$
    </div>

    <p>where $N$ is the total number of counts. In <em>this</em> analysis, $\log(\mathcal{L})$ is used to compare the set of probabilities predicted by a gate set ($p_s$) and the frequencies obtained from a dataset ($f_s$).  Each experiment (or gate sequence) $s$ is associated to two probabilities:  <q>plus</q> has probability $p_s$ and <q>minus</q> has probability $1-p_s$.  The $\log(\mathcal{L})$ contribution of a single gate string $s$ is</p>

    <div class="equation" id="eqGateStringLogL">
      $$ \log(\mathcal{L})_s = N f_s \log(p_s) + N (1-f_s) \log(1-p_s), $$
    </div>

    <p>where $N$ is the number of times the experiment $s$ was performed, $p_s$ is the probability of a <q>plus</q> outcome as predicted by the gate set, and $f_s$ is the observed frequency of <q>plus</q>.  The total log-likelihood for an entire dataset is just the sum</p>

    <div class="equation" id="eqDatasetLogL">
      $$\log(\mathcal{L}) = \sum_{s\in\mathcal{S}}{ \log(\mathcal{L})_s}.$$
    </div>
    
    <p>A theoretical upper bound on the log-likelihood can be found by replacing $p_s$ with $f_s$ in Eq. <a href="#eqGateStringLogL">here</a> and evaluating Eq. <a href="#eqDatasetLogL">here</a>.  We will refer to this quantity as $\log(\mathcal{L})_{ub}$.</p>
    
    <p>Statistical theory has quite a lot to say about the likelihood function (see any of the major textbooks).  Using some of these results, we can predict that if there are $N_p$ free parameters in the gate set that GST is fitting, and GST fits a dataset containing $N_s > N_p$ distinct experiments (gate sequences), then <em>if the gate set model is correct</em>, then two times the difference between $\log(\mathcal{L})_{ub}$ and the maximum $\log(\mathcal{L})$ obtained is a random variable with a $\chi^2_{k}$ distribution, where $k \equiv N_s - N_p$.  Its expected value is $\left\langle \chi^2 \right\rangle = k$, and its standard deviation is $\sqrt{2k}$.  Thus, if the fit is <q>good</q>, then twice $\Delta\log(\mathcal{L}) \equiv \log(\mathcal{L})_{ub} - \max(\log(\mathcal{L}))$ should lie roughly within the interval $[k-\sqrt{2k},k+\sqrt{2k}]$. Thus, by comparing the difference $2\Delta\log(\mathcal{L}) - k$ to $\sqrt{2k}$, one can determine how well the GST estimate was able to fit the data in dataset %(datasetLabel)s.</p>
      
<!-- \iftoggle{LsAndGermsSet}{ -->
    <p>The MLEGST algorithm used to generate this estimate is iterative.  It starts by fitting only data from the shortest gate sequences (which are easy to fit <em>and</em> insensitive to most non-Markovian noise), then successively adds longer and longer sequences (with base sequence length $L\leq 1,2,4,8,\ldots$) to the mix.  Since we get an estimate at each intermediate $L$, it is possible to quantify not just the goodness of the <em>best</em> fit (presented in the previous section), but how the goodness-of-fit behaves as longer and longer sequences are added in.</p>

    <p>This data is presented in Table <a href="#progressTable" class="table"></a>.  What you should be looking for here is whether -- at each value of $L$ -- the $2\Delta\log(\mathcal{L})$ quantity is roughly the same as $k$.  More precisely, is $|2\Delta\log(\mathcal{L})-k|$ less than or equal to $\sqrt{2k}$?  If not, then the model is not fitting as well as it should, which usually indicates non-Markovian noise (or, rarely, that the GST algorithm has simply failed to find a good fit even though one exists).</p>

    <p>As a rough rule of thumb, for GST experiments involving relatively long sequences (e.g. $L\geq100$):</p>
    <ul>
      <li><q>Incredibly good</q> ($\bigstar\bigstar\bigstar\bigstar\bigstar$) experiments have $2\Delta\log(\mathcal{L}) \approx k$, as predicted by theory (and seen in simulations).</li>
      <li><q>Great</q> ($\bigstar\bigstar\bigstar\bigstar$) experiments have $2\Delta\log(\mathcal{L}) \leq 2k$ or so.</li>
      <li><q>Good</q> ($\bigstar\bigstar\bigstar$) experiments have $2\Delta\log(\mathcal{L}) \leq 5k$ or so.</li>
      <li><q>Okay</q> ($\bigstar\bigstar$) experiments have $2\Delta\log(\mathcal{L}) \leq 10k$.</li>
      <li>Experiments in which $2\Delta\log(\mathcal{L}) > 10k$ ($\bigstar$) have very significant non-Markovian noise, and the results in the previous section should be viewed very cautiously.</li>
    </ul>

    <figure id="progressTable" class='tbl'>
      <figcaption><strong>Comparison between the computed and expected maximum $\log(\mathcal{L})$ for different values of $L$</strong>.  $N_S$ and $N_p$ are the number of gate strings and parameters, respectively.  The quantity $2\Delta\log(\mathcal{L})$ measures the goodness of fit of the GST model (small is better) and is expected to lie within $[k-\sqrt{2k},k+\sqrt{2k}]$ where $k = N_s-N_p$. $N_\sigma = (2\Delta\log(\mathcal{L})-k)/\sqrt{2k}$ is the number of standard deviations from the mean (a $p$-value can be straightforwardly derived from $N_\sigma$).  The rating from 1 to 5 stars gives a very crude indication of goodness of fit as explained in the text.</figcaption>
      <!--$p$ is the p-value derived from a $\chi^2_k$ distribution.(For example, if $p=0.05$, then the probability of observing a $\chi^{2}$ value as large as, or larger than, the one indicated in the table is 5%%, assuming the GST model is valid.) -->
      %(progressTable)s
    </figure>

    <h2>Detailed likelihood analysis</h2>
    <p>The aggregated $2\Delta\log(\mathcal{L})$ numbers presented in Table <a href="#progressTable" class="table"></a> tell you how well the GST estimate fits the <em>entire</em> dataset.  If they are in line with theory ($2\Delta\log(\mathcal{L}) \approx k$), then there is little more to be said.  But if the best fit to the data is not good, we can debug it by identifying <em>which</em> experiments are inconsistent with the fit.</p>

    <p>Figure <a href="#bestEstimateColorBoxPlot" class="figure"></a> displays the $2\Delta\log(\mathcal{L})$ contribution from each individual gate sequence (Eq. <a href="#eqGateStringLogL">here</a>).  Each gate sequence corresponds to a single colored <q>pixel</q> in the plot.  Each block of pixels corresponds to a single base sequence (i.e., a germ power), and the individual pixels within a block correspond to the various fiducial sequence pairs between which that base sequence was sandwiched, as indicated in Figure <a href="#colorBoxPlotKeyPlot" class="figure"></a>.  Base sequences are arranged in a grid; different rows correspond to different germs, while different columns correspond to different maximum lengths $L$.  Pixels are labeled with the $2\Delta\log(\mathcal{L})$ contribution for that sequence, and colored appropriately.</p>

    <p>Sequences whose observed frequencies are consistent with a Markovian gate set are shown in gray, with darker shades indicating greater inconsistency with the estimated gate set.  Data shown in red are <em>not</em> consistent with a Markovian gate set.  It may appear contradictory to say that (a) gray is <q>consistent</q> with Markovian, but (b) darker shades indicate <q>greater inconsistency</q>.  The resolution is that the $\chi^2$ values quantify inconsistency with the model, <em>but</em> they themselves are also subject to random fluctuations.  Therefore, even if the data are perfectly consistent with the model, we expect to see (for example) a single $\chi^2_s \geq 10$ once per each 638 experiments.  Observing $\chi^2_s \geq 10$ for any given sequence does suggest that the data from $s$ were relatively surprising, but we also expect to see one such fluctuation if there are more than about 600 experiments.  The gray/red threshold is chosen based on the total number of sequences so that <em>if</em> the data are perfectly Markovian, then the probability of one or more experiments being colored red is only %(linlg_pcntle)s%%.</p>

    <p>Identifying patterns and trends within such <q>pixel plots</q> can aid in identifying specific sources and types of non-Markovian noise which may be to blame if the GST algorithms are unable to produce a <q>good</q> estimate.  For example, it is often the case that all the short sequences [$L = O(1)$] can be fit reasonably well, but the right-hand side of Figure <a href="#bestEstimateColorBoxPlot" class="figure"></a> becomes a sea of red.  This indicates that non-Markovian behavior (potentially due to slow drift of gate set parameters) is becoming more significant for longer experiments.  In other cases, a single row may be particularly bad, indicating that a particular gate or germ is especially problematic (e.g., was not stabilized using dynamical decoupling techniques).  Be cautious in debugging, however -- sometimes bad $\log(\mathcal{L})$ values for a particular gate or germ can result <em>not</em> from faults in that operation, but because another operation failed so badly that it distorted the entire fit (e.g., in trying to fit catastrophically non-Markovian data at Point A, GST ended up failing to fit perfectly good data at Point B).</p>

    <figure id="colorBoxPlotKeyPlot">
      %(colorBoxPlotKeyPlot)s
      <figcaption><strong>Sub-block key for subsequent plots</strong>. Shows how elements of the sub-blocks in Figure <a href="#bestEstimateColorBoxPlot" class="figure"></a> correspond to preparation and measurement fiducial sequences.  Note that the column indicates the fiducial adjacent to state preparation, while the row indicates the fiducial adjacent to measurement.</figcaption>
    </figure>


    <figure id="bestEstimateColorBoxPlot">
      %(bestEstimateColorBoxPlotPages)s
      %(maxLSwitchboard1)s
      <figcaption><strong>$2\Delta\log(\mathcal{L})$ contributions for every individual experiment in the dataset</strong>.   Each pixel represents a single experiment (gate sequence), and its color indicates whether GST was able to fit the corresponding frequency well.  Shades of white/gray are typical. Red squares represent statistically significant evidence for model violation (non-Markovianity), and should appear with probability at most %(linlg_pcntle)s%% if the data really are Markovian. Square blocks of pixels correspond to base sequences (arranged vertically by germ and horizontally by length); each pixel within a block corresponds to a specific choice of pre- and post-fiducial sequences.  See text for further details.</figcaption>
    </figure>

    #iftoggle(ShowScaling)
    
    <figure id="dataScalingColorBoxPlot">
      %(dataScalingColorBoxPlot)s
      <figcaption><strong>Data scaling factor for every individual experiment in the dataset</strong>.   Each pixel represents a single experiment (gate sequence), and its color indicates the amount of scaling that was applied to the original data counts when computing the log-likelihood or $\chi^2$ for this estimate.  Values of 1.0 indicate all of the original data was used, whereas numbers between 0 and 1 indicate that the data counts for the experiement were artificially decreased (usually to improve the fit).</figcaption>
    </figure>
    
    #elsetoggle
    <p>Note: data-scaling color box figure is not shown because none of the estimates in this report have scaled data.</p>
    #endtoggle

    #iftoggle(CompareDatasets)
    
    <p>Since there are multiple data sets in this report, it may be useful to compare them.  The plots below show how likely it is that the data from the selected sets were generated from the same underlying gates.  This analysis is completely independent of GST's numerical estimation protocols: it simply compares the counts obtained for the same gate sequence in different data sets.  For each sequence, a p-value is assigned by treating the data counts as coin flips and comparing two models: 1) the <q>single-distribution</q> model, which adds the counts together and compares their frequency to a single multinomial distribution, and 2) the <q>separate</q> model which separately fits each set of data counts to an independent distribution.</p>

    <figure id="dsComparisonHistogram">
      %(dsComparisonHistogram)s
      %(dscmpSwitchboard)s
      <figcaption><strong>Histogram of p-values comparing two data sets.</strong>  Each gate sequence is assigned a p-value based on how consistent that sequence's counts are between the two selected data sets.  The line shows what would be expected for perfectly consistent data.</figcaption>
    </figure>

    <figure id="dsComparisonBoxPlot">
      %(dsComparisonBoxPlot)s
      <figcaption><strong>Per-sequence p-values comparing two data sets.</strong>  In a similar fashion to other color box plots, this plot shows the p-value of each gate sequence corresponding to how consistent that sequences counts are between the two selected data sets.</figcaption>
    </figure>

    #endtoggle
    
    <!-- End Ls and Germs only section -->

    </section>
    
    <section id="metadata">
      <h1>System and pyGSTi parameters</h1>
      <p>This section contains a raw dump of system information and various pyGSTi parameters.  It's purpose is to stamp this report with parameters indicating how exactly GST was run to create it, as well as to record the software environment in within which the report creation was run.  Note that if the core GST computation was done on a machine different from the one that created this report, the software information contained here will be of less value.</p>

      <figure id="metadataTable" class='tbl'>
        <figcaption><strong>Listing of GST parameters and meta-data</strong>.  These parameters and related metadata describe how the GST computation was performed which led to this report.</figcaption>
        %(metadataTable)s
      </figure>

      <figure id="softwareEnvTable" class='tbl'>
	<figcaption><strong>Listing of the software environment</strong>.  Note that this describes the software environment of the machine used to generate this report, and not necessarily the machine used to perform the core GST gate set estimation.</figcaption>
	%(softwareEnvTable)s
      </figure>
      
    </section>
  </body>
</html>
